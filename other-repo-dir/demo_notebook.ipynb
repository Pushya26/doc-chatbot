{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f04eca5f",
   "metadata": {},
   "source": [
    "# ü§ñ Document Chatbot Demo\n",
    "\n",
    "This notebook demonstrates the key features of the enhanced document chatbot system.\n",
    "\n",
    "## Features Demonstrated:\n",
    "1. Document ingestion from multiple file formats\n",
    "2. Intelligent retrieval with confidence scoring\n",
    "3. Answer generation with citations\n",
    "4. Answer refusal when information is not available\n",
    "5. Performance monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44d7278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path('.').absolute()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from app.chatbot import DocumentChatbot\n",
    "from app.config import get_config\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb37b2e",
   "metadata": {},
   "source": [
    "## 1. Initialize the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc99f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the chatbot\n",
    "print(\"ü§ñ Initializing Document Chatbot...\")\n",
    "chatbot = DocumentChatbot()\n",
    "\n",
    "# Get initial statistics\n",
    "stats = chatbot.get_stats()\n",
    "print(f\"üìä Initial Statistics:\")\n",
    "print(f\"   - Total documents: {stats['vector_store']['total_documents']}\")\n",
    "print(f\"   - Collection: {stats['vector_store']['collection_name']}\")\n",
    "print(f\"   - Chunk size: {stats['config']['chunk_size']}\")\n",
    "print(f\"   - Retrieval K: {stats['config']['retrieval_k']}\")\n",
    "print(\"‚úÖ Chatbot initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c67c115",
   "metadata": {},
   "source": [
    "## 2. Document Ingestion Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc836848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data folder exists\n",
    "data_folder = project_root / \"data\"\n",
    "print(f\"üìÅ Checking data folder: {data_folder}\")\n",
    "\n",
    "if not data_folder.exists():\n",
    "    print(\"‚ùå Data folder not found. Creating it...\")\n",
    "    data_folder.mkdir(exist_ok=True)\n",
    "    print(\"‚ö†Ô∏è  Please add documents (PDF, TXT, MD, DOCX) to the 'data' folder and re-run this cell\")\n",
    "else:\n",
    "    # List files in data folder\n",
    "    files = list(data_folder.glob(\"*\"))\n",
    "    print(f\"üìÑ Found {len(files)} files in data folder:\")\n",
    "    for file in files[:5]:  # Show first 5 files\n",
    "        print(f\"   - {file.name}\")\n",
    "    if len(files) > 5:\n",
    "        print(f\"   ... and {len(files) - 5} more files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199caf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset knowledge base and ingest documents\n",
    "print(\"üóëÔ∏è  Resetting knowledge base...\")\n",
    "reset_result = chatbot.reset_knowledge_base()\n",
    "print(f\"Reset result: {reset_result['success']}\")\n",
    "\n",
    "if data_folder.exists() and list(data_folder.glob(\"*\")):\n",
    "    print(f\"üìö Ingesting documents from: {data_folder}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    result = chatbot.ingest_documents(str(data_folder))\n",
    "    \n",
    "    if result['success']:\n",
    "        print(f\"‚úÖ {result['message']}\")\n",
    "        stats = result['stats']\n",
    "        print(f\"üìä Ingestion Statistics:\")\n",
    "        print(f\"   - New chunks: {stats.get('new_chunks', 0)}\")\n",
    "        print(f\"   - Total documents: {stats.get('total_documents', 0)}\")\n",
    "        print(f\"   - Processing time: {stats.get('processing_time', 0):.2f}s\")\n",
    "    else:\n",
    "        print(f\"‚ùå {result['message']}\")\n",
    "else:\n",
    "    print(\"‚ùå No documents found to ingest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ca494",
   "metadata": {},
   "source": [
    "## 3. Question Answering Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb776b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example questions to test the system\n",
    "example_questions = [\n",
    "    \"What is machine learning?\",\n",
    "    \"What are the key principles mentioned in the document?\",\n",
    "    \"How should I approach model evaluation?\",\n",
    "    \"What is deep learning?\",  # This might not be in the documents\n",
    "    \"Can you summarize the main topics covered?\"\n",
    "]\n",
    "\n",
    "print(f\"üìù Testing {len(example_questions)} example questions...\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc737b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display results nicely\n",
    "def display_answer(question, result, question_num):\n",
    "    print(f\"\\nüîπ Question {question_num}: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"ü§ñ Answer:\")\n",
    "    print(result['answer'])\n",
    "    \n",
    "    if result['citations']:\n",
    "        print(f\"\\nüìö Citations: {', '.join(result['citations'])}\")\n",
    "    \n",
    "    print(f\"\\nüìä Confidence: {result['confidence']:.3f}\")\n",
    "    print(f\"‚è±Ô∏è  Response time: {result['total_time']:.2f}s\")\n",
    "    \n",
    "    if result['retrieval_results']:\n",
    "        print(f\"\\nüîç Top retrieved source:\")\n",
    "        top_result = result['retrieval_results'][0]\n",
    "        print(f\"   Source: {top_result['source']} (page {top_result['page']})\")\n",
    "        print(f\"   Similarity score: {top_result['score']}\")\n",
    "        print(f\"   Content preview: {top_result['content'][:100]}...\")\n",
    "    \n",
    "    print(\"\\n\" + \".\" * 60)\n",
    "\n",
    "# Test each question\n",
    "results = []\n",
    "for i, question in enumerate(example_questions, 1):\n",
    "    result = chatbot.ask_question(question)\n",
    "    display_answer(question, result, i)\n",
    "    \n",
    "    # Store for analysis\n",
    "    results.append({\n",
    "        'question': question,\n",
    "        'answer_length': len(result['answer']),\n",
    "        'confidence': result['confidence'],\n",
    "        'response_time': result['total_time'],\n",
    "        'has_citations': len(result['citations']) > 0,\n",
    "        'num_sources': len(result['retrieval_results'])\n",
    "    })\n",
    "    \n",
    "    time.sleep(1)  # Brief pause between questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b141d6aa",
   "metadata": {},
   "source": [
    "## 4. Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86334f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for analysis\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "print(\"üìà Performance Analysis\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Average response time: {df['response_time'].mean():.2f}s\")\n",
    "print(f\"Max response time: {df['response_time'].max():.2f}s\")\n",
    "print(f\"Min response time: {df['response_time'].min():.2f}s\")\n",
    "print(f\"Average confidence: {df['confidence'].mean():.3f}\")\n",
    "print(f\"Questions with citations: {df['has_citations'].sum()}/{len(df)}\")\n",
    "print(f\"Average answer length: {df['answer_length'].mean():.0f} characters\")\n",
    "\n",
    "# Display the results table\n",
    "print(\"\\nüìä Detailed Results:\")\n",
    "display_df = df[['question', 'confidence', 'response_time', 'has_citations']].copy()\n",
    "display_df['question'] = display_df['question'].str[:50] + '...'  # Truncate for display\n",
    "display_df.columns = ['Question', 'Confidence', 'Time (s)', 'Has Citations']\n",
    "print(display_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2f61d0",
   "metadata": {},
   "source": [
    "## 5. Interactive Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4b0a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive question answering\n",
    "def ask_interactive_question():\n",
    "    question = input(\"üîπ Your question (or 'quit' to exit): \").strip()\n",
    "    \n",
    "    if question.lower() in ['quit', 'exit', 'q']:\n",
    "        return False\n",
    "    \n",
    "    if not question:\n",
    "        print(\"Please enter a question.\")\n",
    "        return True\n",
    "    \n",
    "    print(\"\\nüîç Searching for relevant information...\")\n",
    "    result = chatbot.ask_question(question)\n",
    "    \n",
    "    print(f\"\\nü§ñ Answer:\")\n",
    "    print(result['answer'])\n",
    "    \n",
    "    if result['citations']:\n",
    "        print(f\"\\nüìö Sources: {', '.join(result['citations'])}\")\n",
    "    \n",
    "    print(f\"\\nüìä Confidence: {result['confidence']:.3f} | ‚è±Ô∏è Time: {result['total_time']:.2f}s\")\n",
    "    print(\"\\n\" + \"-\" * 60)\n",
    "    \n",
    "    return True\n",
    "\n",
    "print(\"üí¨ Interactive Mode\")\n",
    "print(\"You can now ask questions about your documents!\")\n",
    "print(\"Type 'quit' to exit.\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Note: In Jupyter, this will only work if run interactively\n",
    "# For demo purposes, we'll just show how it would work\n",
    "print(\"Note: In Jupyter notebooks, interactive input may not work properly.\")\n",
    "print(\"To try interactive mode, run: python main.py interactive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2430a8c1",
   "metadata": {},
   "source": [
    "## 6. Document Search Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5ec76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate document search without answer generation\n",
    "search_query = \"machine learning\"\n",
    "print(f\"üîç Searching for: '{search_query}'\")\n",
    "\n",
    "search_results = chatbot.search_documents(search_query, k=5)\n",
    "\n",
    "print(f\"\\nüìÑ Found {len(search_results)} relevant documents:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, result in enumerate(search_results, 1):\n",
    "    print(f\"\\n{i}. {result['source']} (Page {result['page']})\")\n",
    "    print(f\"   Similarity Score: {result['similarity_score']:.3f}\")\n",
    "    print(f\"   Citations: {', '.join(result['citations'])}\")\n",
    "    print(f\"   Content: {result['content'][:200]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c037eb",
   "metadata": {},
   "source": [
    "## 7. System Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6c84e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get comprehensive system information\n",
    "final_stats = chatbot.get_stats()\n",
    "available_sources = chatbot.get_available_sources()\n",
    "\n",
    "print(\"üìä Final System Statistics\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Total documents in knowledge base: {final_stats['vector_store']['total_documents']}\")\n",
    "print(f\"Collection name: {final_stats['vector_store']['collection_name']}\")\n",
    "print(f\"Persist directory: {final_stats['vector_store']['persist_directory']}\")\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è Configuration:\")\n",
    "print(f\"Chunk size: {final_stats['config']['chunk_size']}\")\n",
    "print(f\"Chunk overlap: {final_stats['config']['chunk_overlap']}\")\n",
    "print(f\"Retrieval K: {final_stats['config']['retrieval_k']}\")\n",
    "print(f\"Confidence threshold: {final_stats['config']['confidence_threshold']}\")\n",
    "\n",
    "print(f\"\\nüìö Available Sources ({len(available_sources)}):\")\n",
    "for source in available_sources:\n",
    "    print(f\"   - {source}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d8de58",
   "metadata": {},
   "source": [
    "## 8. Next Steps\n",
    "\n",
    "This notebook demonstrated the core functionality of the Document Chatbot system. Here are some next steps you can try:\n",
    "\n",
    "### Using the System\n",
    "1. **Add more documents**: Place additional PDF, TXT, MD, or DOCX files in the `data/` folder\n",
    "2. **Try the CLI**: Run `python main.py --help` to see all available commands\n",
    "3. **Use the web interface**: Run `streamlit run streamlit_app.py` for a web UI\n",
    "4. **Try the FastAPI**: Run `python fastapi_app.py` for a REST API\n",
    "\n",
    "### Customization\n",
    "1. **Adjust configuration**: Edit `app/config.py` to change chunk sizes, thresholds, etc.\n",
    "2. **Add LLM model**: Provide a model path for better answer generation\n",
    "3. **Tune performance**: Adjust retrieval parameters based on your documents\n",
    "\n",
    "### Advanced Features\n",
    "1. **Citation formatting**: Customize how citations are displayed\n",
    "2. **Confidence tuning**: Adjust thresholds for answer refusal\n",
    "3. **Performance monitoring**: Track response times and accuracy\n",
    "\n",
    "**Happy chatting with your documents! üéâ**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
